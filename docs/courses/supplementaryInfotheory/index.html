<!doctype html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta property="og:title" content="Centre for Networked Intelligence"><meta property="og:description" content="Centre for Networked Intelligence (CNI) is a research group at the Indian Institute of Science Bangalore"><meta property="og:url" content=""><meta property="og:image" content="/assets/img/Logos/cni_blue_round_1200x1200.png"><meta property="og:image:alt" content="CNI logo"><meta property="og:image:type" content="image/png"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="1200"><meta property="og:type" content="website"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="Centre for Networked Intelligence"><meta name="twitter:description" content="Centre for Networked Intelligence (CNI) is a research group at the Indian Institute of Science Bangalore"><meta name="twitter:image" content="/assets/img/Logos/cni_blue_round_1200x1200.png"><meta name="twitter:image:alt" content="CNI logo"><link rel="icon" href="/assets/images/tab_symbol.png" type="image/png"><title>Supplementary Information Theory | CNI</title><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet"><link href="https://getbootstrap.com/docs/5.3/assets/css/docs.css" rel="stylesheet"><link href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css" rel="stylesheet"><script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" rel="stylesheet"><script type="text/javascript">MathJax = {
        tex: { inlineMath: [['$','$'], ['\\(','\\)']] },
        svg: { fontCache: 'global' }
      };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><link rel="stylesheet" href="/assets/css/navbar_style.css"><link rel="stylesheet" href="/assets/css/footer.css"><style>/* Light theme */
      .light-theme {
        background-color: #F7F7F7;
        color: #212121;
        td {
          color: #212121;
        }
      }
      
      /* Dark theme */
      .dark-theme {
        background-color: #212121;
        color: #ffffff;
        td {
          color: white;
        }
      }</style><script>// Check if the browser supports the prefers-color-scheme media query
      function applyTheme() {
        const fallbackTheme = 'light';
        const userPrefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;

        // Apply the system theme or fallback
        if (userPrefersDark) {
          document.body.classList.add('dark-theme');
        } else if (window.matchMedia('(prefers-color-scheme: light)').matches) {
          document.body.classList.add('light-theme');
        } else {
          document.body.classList.add(fallbackTheme + '-theme');
        }
      }

      // Apply theme on page load
      window.onload = applyTheme;</script></head><body><nav class="navbar navbar-expand-lg custom-navbar"><div class="container-fluid"><a class="navbar-brand" href="/"><img src="/assets/images/cni_logo.png" alt="CNI logo" style="height: 60px;"> </a><button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarText" aria-controls="navbarText" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse justify-content-end" id="navbarText"><ul class="navbar-nav"><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" onmouseover="this.style.color='var(--hyperlink-clr)';" onmouseout="this.style.color='#ffffff';">Outreach</a><ul class="dropdown-menu"><li><a class="dropdown-item" href="/network-seminar/">Seminars</a></li><li><a class="dropdown-item" href="/newsletter/latest/">Newsletters</a></li><li><a class="dropdown-item" href="/courses/">Courses</a></li><li><a class="dropdown-item" href="/summer-school/">Summer School</a></li><li><a class="dropdown-item" href="/news/">CNI in News</a></li><li><a class="dropdown-item" href="/hackathons">Hackathons</a></li><li><a class="dropdown-item" href="/workshops/">Workshops</a></li></ul></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" onmouseover="this.style.color='var(--hyperlink-clr)';" onmouseout="this.style.color='#ffffff';">Research</a><ul class="dropdown-menu"><li><a class="dropdown-item" href="/projects/">Projects</a></li><li><a class="dropdown-item" href="/publications/">Publications</a></li><li><a class="dropdown-item" href="/highlights/">Highlights</a></li></ul></li><li class="nav-item dropdown"><a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" onmouseover="this.style.color='var(--hyperlink-clr)';" onmouseout="this.style.color='#ffffff';">People</a><ul class="dropdown-menu"><li><a class="dropdown-item" href="/faculty/">Faculty</a></li><li><a class="dropdown-item" href="/staff/">Staff</a></li><li><a class="dropdown-item" href="/phd-fellows/">PhD Fellows</a></li><li><a class="dropdown-item" href="/mtech-fellows/">MTech Fellows</a></li></ul></li><li class="nav-item"><a class="nav-link" href="/opportunities/">Opportunities</a></li></ul></div></div></nav><div class="container-fluid mt-2 mb-2" align="center"><h2>Supplementary Information Theory</h2></div><div class="mx-auto" style="max-width: 800px;"><article class="container-fluid mt-2 mb-2"><h2>Lecture 1 - Data Compression</h2><h4>Contributor - Sahasranand Kodinthirapully Ramanadhan</h4><p>In the first part of this tutorial, we discuss fixed-length, almost lossless compression. We start by deriving single-shot bounds for the minimum length of block source codes and then extend them to yield the optimal source code rate for a discrete memoryless source. In the second part, we characterize the minimum expected codeword lengths for variable-length, lossless compression using uniquely decodable codes, prefix-free codes, and non-singular codes.</p><div class="container-fluid" align="center"><div class="ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/5Ypu8cWyXqU" title="Lecture 1 - Data Compression" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div></div><h2>Lecture 2 - ECC</h2><h4>Contributor - Vinay Kumar Bindiganavile Ramadas</h4><p>In this lecture, we first review Shannon’s channel coding theorem and establish the need for designing codes which can be implemented in practice. A brief history of error correction codes and few practical examples are showcased. This is followed by a description of linear codes with the spotlight on Hamming codes. Decoding algorithms for these are outlined. Random linear codes are shown to achieve the capacity for the BSC. Recent advances in the design of capacity-achieving/ capacity-approaching codes and the techniques used are highlighted.</p><div class="container-fluid" align="center"><div class="ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/h_FP6haDrvM" title="Lecture 2 - ECC" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div></div><h2>Lecture 3 - Quantization</h2><h4>Contributor - Shubham Kumar Jha</h4><p>In this lecture, we will study about the following:</p><ol><li>Scalar quantization: Uniform quantizers, performance measures, high resolution</li><li>Concept of Dithering.</li></ol><div class="container-fluid" align="center"><div class="ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/8yjGxdEopVE" title="Lecture 3 - Quantization" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div></div><h2>Lecture 4 - Information-theoretic lower bounds</h2><h4>Contributor - Aditya Vikram Singh</h4><p>Information-theoretic lower bounds in statistics: Fano and Assouad methods.</p><div class="container-fluid" align="center"><div class="ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/F9ybX5ve7Ys" title="Lecture 4 - Information-theoretic lower bounds" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div></div><h2>Lecture 5 - Information Theory and Large Deviations</h2><h4>Contributor - Sarath Ampadi Yasodharan</h4><p>In this lecture we study the probabilities of large deviations of the empirical measure of n independent and identically distributed (i.i.d.) random variables from their true distribution gamma. We first introduce a variational formula for positive functions of i.i.d. random variables in terms of the relative entropy gamma We then use this to prove Sanov’s theorem, i.e., we show that the probability that the empirical measure is close to a distribution mu decays as shown in the video.</p><div class="container-fluid" align="center"><div class="ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/UGmnmR5lFuM" title="Lecture 5 - Information Theory and Large Deviations" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div></div><h2>Lecture 6 - Information Geometry</h2><h4>Contributor - Karthik Periyapatna Narayanaprasad</h4><p>In this lecture we will discuss Information Geometry and Its Applications to Statistics</p><div class="container-fluid" align="center"><div class="ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/CdPRIGeHuEk" title="Lecture 6 - Information Geometry" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div></div><h2>Lecture 7 - Concentration Inequalities</h2><h4>Contributor - Lekshmi Ramesh</h4><p>In this lecture, we will cover the basics of a very useful set of tools that are used to study tail probabilities of random variables. We will start by introducing a basic toolkit for studying sums of independent random variables –this will include the Chernoff, Hoeffding, and Bernstein bounds, and then cover some techniques for handling more general functions of random variables. We will then see how ideas from information theory can be used to derive more general inequalities, and this will be demonstrated by a brief discussion of the entropy method. Towards the end of the lecture, we will see some applications of these tools.</p><div class="container-fluid" align="center"><div class="ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/wOfTC0yzTxo" title="Lecture 7 - Concentration Inequalities" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div></div><h2>Lecture 8 - Shannon's Channel Coding Theorem</h2><h4>Contributor - Shubham Kumar Jha</h4><p>In this lecture, we will study about repetition codes, Shannon’s channel coding theorem, and evaluate the capacities for BEC, BSC, AWGN channels.</p><div class="container-fluid" align="center"><div class="ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/gzMrpCCQ0cs" title="Lecture 8 - Shannon's Channel Coding Theorem" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe></div></div></article></div><footer class="site-footer"><div class="footer-container"><a href="mailto:contact.cni@iisc.ac.in" title="Email" target="_blank"><i class="fa-solid fa-envelope"></i> </a><a href="https://github.com/cni-iisc" title="GitHub" target="_blank"><i class="fa-brands fa-github"></i> </a><a href="https://x.com/cni_iisc" title="X" target="_blank"><i class="fa-brands fa-x-twitter"></i> </a><a href="https://www.linkedin.com/company/cni-iisc" title="LinkedIn" target="_blank"><i class="fa-brands fa-linkedin"></i> </a><a href="https://www.youtube.com/@centrefornetworkedintellig5324" title="YouTube" target="_blank"><i class="fa-brands fa-youtube"></i> </a><a href="https://www.instagram.com/cni_iisc/" title="Instagram" target="_blank"><i class="fa-brands fa-instagram"></i></a><p>&copy; 2025 Centre for Networked Intelligence. All rights reserved.</p><p>Last updated: January 31, 2025</p></div></footer></body></html>